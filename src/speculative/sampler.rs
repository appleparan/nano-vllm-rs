//! Rejection sampler for speculative decoding.
//!
//! Implements the token verification algorithm that ensures the output
//! distribution matches the target model exactly.

use candle_core::{D, IndexOp, Result, Tensor};
use rand::distributions::Distribution;
use rand::{Rng, SeedableRng};

/// Rejection sampler for speculative decoding.
///
/// Verifies draft tokens against target model distribution and decides
/// which tokens to accept or reject.
///
/// ## Algorithm
///
/// For each draft token `t` at position `i`:
///
/// 1. Compute acceptance probability: `α = min(1, P_target[t] / P_draft[t])`
/// 2. Sample `u ~ Uniform(0, 1)`
/// 3. If `u < α`: accept token, continue to next
/// 4. Else: reject token, resample from adjusted distribution
///
/// The adjusted distribution ensures correctness:
/// `P_adjusted = max(0, P_target - P_draft) / Z`
///
/// where `Z` is the normalization constant.
#[derive(Debug)]
pub struct RejectionSampler {
    rng: rand::rngs::StdRng,
}

impl RejectionSampler {
    /// Create a new rejection sampler with random seed.
    pub fn new() -> Self {
        Self {
            rng: rand::rngs::StdRng::from_entropy(),
        }
    }

    /// Create a new rejection sampler with a specific seed for reproducibility.
    pub fn with_seed(seed: u64) -> Self {
        Self {
            rng: rand::rngs::StdRng::seed_from_u64(seed),
        }
    }

    /// Verify draft tokens against target distribution.
    ///
    /// # Arguments
    ///
    /// * `draft_tokens` - Token IDs generated by draft model
    /// * `draft_logits` - Logits from draft model [K, vocab_size]
    /// * `target_logits` - Logits from target model [K+1, vocab_size]
    /// * `temperature` - Sampling temperature (applied to both distributions)
    ///
    /// # Returns
    ///
    /// `(accepted_tokens, final_token, num_accepted)`:
    /// - `accepted_tokens`: Draft tokens that were accepted
    /// - `final_token`: Final token (either from acceptance or resampling)
    /// - `num_accepted`: Number of draft tokens accepted (0 to K)
    pub fn verify(
        &mut self,
        draft_tokens: &[u32],
        draft_logits: &Tensor,
        target_logits: &Tensor,
        temperature: f32,
    ) -> Result<(Vec<u32>, u32, usize)> {
        let k = draft_tokens.len();

        // Validate shapes
        let draft_shape = draft_logits.dims();
        let target_shape = target_logits.dims();

        if draft_shape.len() != 2 || target_shape.len() != 2 {
            return Err(candle_core::Error::Msg(format!(
                "Expected 2D tensors, got draft: {draft_shape:?}, target: {target_shape:?}"
            )));
        }

        if draft_shape[0] != k {
            return Err(candle_core::Error::Msg(format!(
                "Draft logits first dim {} != num draft tokens {}",
                draft_shape[0], k
            )));
        }

        if target_shape[0] != k + 1 {
            return Err(candle_core::Error::Msg(format!(
                "Target logits first dim {} != K+1 {}",
                target_shape[0],
                k + 1
            )));
        }

        let mut accepted = Vec::with_capacity(k);

        // Apply temperature and convert to probabilities
        let draft_probs = self.logits_to_probs(draft_logits, temperature)?;
        let target_probs = self.logits_to_probs(target_logits, temperature)?;

        for (i, &draft_token) in draft_tokens.iter().enumerate() {
            // Get probabilities for the draft token
            let p_draft = self.get_prob(&draft_probs, i, draft_token)?;
            let p_target = self.get_prob(&target_probs, i, draft_token)?;

            // Acceptance probability: α = min(1, P_target / P_draft)
            let alpha = if p_draft > 0.0 {
                (p_target / p_draft).min(1.0)
            } else {
                // If draft probability is 0, always reject
                0.0
            };

            // Sample u ~ Uniform(0, 1)
            let u: f32 = self.rng.r#gen();

            if u < alpha {
                // Accept the draft token
                accepted.push(draft_token);
            } else {
                // Reject: sample from adjusted distribution
                let final_token = self.sample_adjusted(&target_probs, &draft_probs, i)?;
                let num_accepted = accepted.len();
                return Ok((accepted, final_token, num_accepted));
            }
        }

        // All K tokens accepted, sample K+1 from target
        let final_token = self.sample_from_probs(&target_probs, k)?;
        Ok((accepted, final_token, k))
    }

    /// Convert logits to probabilities with temperature scaling.
    fn logits_to_probs(&self, logits: &Tensor, temperature: f32) -> Result<Tensor> {
        let scaled = if temperature != 1.0 && temperature > 0.0 {
            (logits / temperature as f64)?
        } else if temperature == 0.0 {
            // For greedy, we'll handle this separately
            logits.clone()
        } else {
            logits.clone()
        };

        // Apply softmax
        candle_nn::ops::softmax(&scaled, D::Minus1)
    }

    /// Get probability of a specific token at a specific position.
    fn get_prob(&self, probs: &Tensor, position: usize, token: u32) -> Result<f32> {
        let row = probs.i(position)?;
        let p = row.i(token as usize)?.to_scalar::<f32>()?;
        Ok(p)
    }

    /// Sample from adjusted distribution: P_adjusted = max(0, P_target - P_draft) / Z
    fn sample_adjusted(
        &mut self,
        target_probs: &Tensor,
        draft_probs: &Tensor,
        position: usize,
    ) -> Result<u32> {
        let target_row = target_probs.i(position)?;
        let draft_row = draft_probs.i(position)?;

        // Compute adjusted distribution: max(0, P_target - P_draft)
        let adjusted = target_row.sub(&draft_row)?;
        let adjusted = adjusted.maximum(&Tensor::zeros_like(&adjusted)?)?;

        // Normalize
        let sum = adjusted.sum_all()?.to_scalar::<f32>()?;

        if sum <= 0.0 {
            // Fallback to target distribution if adjusted is all zeros
            return self.sample_from_probs(target_probs, position);
        }

        let normalized = (&adjusted / sum as f64)?;

        // Sample
        self.sample_from_tensor(&normalized)
    }

    /// Sample a token from probability distribution at given position.
    fn sample_from_probs(&mut self, probs: &Tensor, position: usize) -> Result<u32> {
        let row = probs.i(position)?;
        self.sample_from_tensor(&row)
    }

    /// Sample a token from a 1D probability tensor.
    fn sample_from_tensor(&mut self, probs: &Tensor) -> Result<u32> {
        let probs_vec: Vec<f32> = probs.to_vec1()?;

        // Renormalize to ensure sum = 1
        let sum: f32 = probs_vec.iter().sum();
        let normalized: Vec<f64> = probs_vec.iter().map(|&p| (p / sum) as f64).collect();

        // Filter out invalid probabilities
        let normalized: Vec<f64> = normalized
            .iter()
            .map(|&p| if p.is_nan() || p < 0.0 { 0.0 } else { p })
            .collect();

        let sum: f64 = normalized.iter().sum();
        if sum <= 0.0 {
            // If all probabilities are zero/invalid, return first token
            return Ok(0);
        }

        let normalized: Vec<f64> = normalized.iter().map(|&p| p / sum).collect();

        // Sample using weighted distribution
        let dist = rand::distributions::WeightedIndex::new(&normalized)
            .map_err(|e| candle_core::Error::Msg(format!("Failed to create distribution: {e}")))?;

        let sampled_idx = dist.sample(&mut self.rng);
        Ok(sampled_idx as u32)
    }
}

impl Default for RejectionSampler {
    fn default() -> Self {
        Self::new()
    }
}
